{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Metrics\n",
    "\n",
    "## Labels Correologram\n",
    "![Labels Correologram](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/labels_correlogram.jpg)\n",
    "\n",
    "- This plot gives insights into the distribution of the bounding box coordinates and sizes (width and height) of the labeled objects in the dataset.\n",
    "- The scatter plots and histograms show the distribution of the x (center x-coordinate of the box), y (center y-coordinate of the box), width, and height of the bounding boxes. Most objects appear to be centrally located with a wide distribution in size.\n",
    "- There is a noticeable concentration of boxes in the central region, which might be due to the nature of the dataset (e.g., crops and weeds are usually found in the center of the images).\n",
    "\n",
    "## Labels Distribution and Bounding Box Annotations\n",
    "![Labels Distribution and Bounding Box Annotations](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/labels.jpg)\n",
    "\n",
    "- The first bar chart indicates the number of instances for each class, showing that 'crop' instances outnumber 'weed' instances. This could suggest a class imbalance which can affect the model training and classification performance.\n",
    "- The second plot appears to show many overlapping bounding boxes, likely representing the location and scale of objects within the images. The density of the boxes indicates that many objects are centrally located with a similar size, which corresponds with the observations from the correlogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "## Confusion Matrix Normalized\n",
    "![Confusion Matrix Normalized](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/confusion_matrix_normalized.png)\n",
    "\n",
    "- his matrix shows the performance of the classification model. Each row represents the instances in a predicted class, while each column represents the instances in an actual class.\n",
    "- The diagonal values (0.79 for crop, 0.82 for weed, 0.21 for background) represent the normalized number of correct predictions for each class. These are relatively high for crop and weed, suggesting good classification performance. However, the value for background is lower, indicating less accuracy in distinguishing background from crops/weeds.\n",
    "- The off-diagonal values represent misclassifications. For example, crops are sometimes misclassified as background (0.18), and weeds are misclassified as crops (0.03) or background (0.18).\n",
    "\n",
    "## Confusion Matrix\n",
    "![Confusion Matrix](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/confusion_matrix.png)\n",
    "\n",
    "- This matrix displays the absolute number of predictions for each class, contrasting with the normalized matrix you provided earlier.\n",
    "- The majority of predictions are correct, with high values on the diagonal (185 for 'crop', 150 for 'weed'). Some misclassifications are evident, with 'crop' occasionally mislabeled as 'background' (42 times) and 'weed' as 'background' (13 times).\n",
    "- The absolute numbers can be helpful for understanding the scale of misclassifications in terms of actual counts, which is crucial for large datasets.\n",
    "\n",
    "\n",
    "## Precision-Recall Curve\n",
    "![Precision-Recall Curve](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/PR_curve.png)\n",
    "\n",
    "- This graph plots the precision (y-axis) against the recall (x-axis) for different threshold settings. Precision is the ratio of true positive predictions to the total positive predictions, and recall is the ratio of true positive predictions to the actual positive instances.\n",
    "- The areas under the curves (AUC) for crop (0.862), weed (0.821), and all classes combined (0.842 mAP@0.5) are indicative of the model's effectiveness in distinguishing between classes. Higher AUC values are better, and these values suggest the model is performing well, especially for crop classification.\n",
    "\n",
    "## Recall-Confidence Curve\n",
    "![Recall-Confidence Curve](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/R_curve.png)\n",
    "\n",
    "- This curve shows the recall over different levels of confidence threshold. The model's confidence threshold can be adjusted to prioritize either recall or precision.\n",
    "- The chart shows that the recall for all classes is high across various confidence levels, reaching a maximum recall of 0.94 at a confidence threshold of 0.000. This suggests that at lower confidence thresholds, the model can retrieve most of the positive samples.\n",
    "\n",
    "## F1-Confidence CUrve\n",
    "![F1-Confidence Curve](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/F1_curve.png)\n",
    "\n",
    "- The F1 score is the harmonic mean of precision and recall, providing a balance between the two. It is particularly useful when the class distribution is uneven.\n",
    "- The curve indicates the model's F1 score across different confidence thresholds. The highest F1 score achieved is 0.81 at a confidence level of 0.290, showing a good balance between precision and recall at that particular threshold.\n",
    "\n",
    "## Precision-COnfidence Curve\n",
    "![Precision-Confidence Curve](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/P_curve.png)\n",
    "\n",
    "- This graph plots the precision of the model across various confidence thresholds. It's important for determining at what confidence level the precision starts to drop, which can be critical for applications where false positives are costly.\n",
    "- The chart shows a high precision (1.00) at a high confidence threshold (0.901) for all classes, indicating the model is highly accurate when it is highly confident in its predictions. However, it also indicates a drop in precision for the 'weed' class at lower confidence thresholds, suggesting a higher rate of false positives for this class.\n",
    "\n",
    "## Training Results\n",
    "![Training Results](/Users/williamduran/Documents/ml_project_crop_vs_weed/runs/detect/train/results.png)\n",
    "\n",
    "- These plots show the model's loss and performance metrics over the course of training epochs.\n",
    "- Loss plots (train/box_loss, train/cls_loss, train/df_loss, val/box_loss, val/cls_loss, val/df_loss) demonstrate how well the model is fitting the training data and generalizing to validation data. The losses are decreasing, which suggests good learning progress.\n",
    "- The metrics plots (metrics/precision(B), metrics/recall(B), metrics/mAP50(B), metrics/mAP50-95(B)) illustrate the precision, recall, and mean average precision at different IoU (Intersection over Union) thresholds. Precision and recall are increasing and plateauing, which is a positive sign, while the mean average precision (mAP) is also increasing, indicating improvements in model performance over time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
